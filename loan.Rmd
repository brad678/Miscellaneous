---
title: "Loan Prediction"
output: 
  html_document: 
    smart: no
---

### Project details: 

####Domain: Banking and Finance
####Project: Loan Prediction
####Data: loan.zip

####Description:
This data corresponds to a set of financial transactions associated with individuals. You are provided with over one thousand observations (test + train) and nearly 13 features. Each observation is independent from the previous.

####Variable Description:

Loan_ID (Unique Loan ID)                                        
Gender (Male/ Female)                                  
Married (Applicant married (Y/N))                                                       
Dependents (Number of dependents)                            
Education (Applicant Education (Graduate/ Under Graduate))                    
Self_Employed (Self-employed (Y/N))                   
ApplicantIncome (Applicant income)                                                        
CoapplicantIncome (Coapplicant income)                                                    
LoanAmount (Loan amount in thousands)                                                    
Loan_Amount_Term (Term of loan in months)                                                        
Credit_History (Credit history meets guidelines. 1-good, 0-not good)    
Property_Area (Urban/ Semi Urban/ Rural)                                                         
Loan_Status (Loan approved (Y/N))                                                                                                                                                                                         


####Objective:

This project asks you to determine whether a loan will get approved or not. Also, try to find good insights with a financial management perspective.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, message=FALSE, warning=FALSE}
library(tidyr)
library(dplyr)
library(ggplot2)
library(caret)
```

### Loading the data

```{r}

loan_train <- read.csv('train_u6lujuX_CVtuZ9i.csv',na.strings = c('NA',''))
summary(loan_train)
glimpse(loan_train)

loan_train$Loan_ID <- as.character(loan_train$Loan_ID)

```

Can find the missing values in:

- gender (13)         
- married (3)           
- dependents (15)                   
- self-employed (32)            
- loan amount (22)            
- loan amount term (14)           
- credit history (50)         


### Finding columns and rows with missing values using function
```{r}
miss <- function(x) {
 cat('\nThe columns having missing values are:')
 for(i in 1:ncol(x)) {
  if(length(x[i][is.na(x[i])]) > 0) {
    cat('\n',names(x[i]),':',length(x[i][is.na(x[i])]))
  }
 } 
  cat('\n\nThe number of rows with missing values are:',nrow(x)-nrow(na.omit(x)))
  cat('\nThe proportion of missing values is:',signif((nrow(x)-nrow(na.omit(x)))/nrow(x),2))
}

miss(loan_train)
```

### Use kNN imputaion to handle missing values (k is choosen as square root of obs.)
### For numerical data, weighted average is used. The data points that are near are weighted more than far away data points.
### For Categorical data, mode is used

```{r, message=FALSE, warning=FALSE}
library(VIM)     #for kNN
library(laeken)  #for weightedMean

loan_train1 <- kNN(loan_train,variable=c('Gender','Married','Dependents','Self_Employed','LoanAmount','Loan_Amount_Term','Credit_History'),k=23,numFun = weightedMean,weightDist=TRUE)

summary(loan_train1)
glimpse(loan_train1)


```


### Remove the extra columns created by kNN imputation. 
### Validate any missing values are present


```{r}
loan_train1 <- loan_train1[-c(14:20)]
miss(loan_train1)

```

### Data Visualization

```{r}

ggplot(data=loan_train1,aes(Loan_Status,LoanAmount))+geom_boxplot()+labs(title='Loan Status vs Loan Amount')

ggplot(data=loan_train1,aes(Loan_Status,ApplicantIncome))+geom_boxplot()+labs(title='Loan Status vs Applicant Income')

ggplot(data=loan_train1,aes(LoanAmount,ApplicantIncome,color=Loan_Status))+geom_point()+labs(title='Loan Amount vs Applicant Income - for various Loan status')

ggplot(data=loan_train1,aes(LoanAmount,ApplicantIncome))+geom_point()+facet_wrap(~Loan_Status)+labs(title='Loan Amount vs Applicant Income - for various Loan status')

#checking if some relation between self employment and loan status
tab <- table(loan_status=loan_train1$Loan_Status,self_employed=loan_train1$Self_Employed)
cat('\nThe proportions of self employment - for various loan status:\n')
prop.table(tab,2)

#checking if some relation between Credit history and loan status
tab <- table(loan_status=loan_train1$Loan_Status,credit_history=loan_train1$Credit_History)
cat('\nThe proportions of credit history - for various loan status:\n')
prop.table(tab,2)
 

#checking if some relation between Coapplicant income and loan status
tab <- table(loan_status=loan_train1$Loan_Status,coapp_inc_0=loan_train1$CoapplicantIncome==0)
cat('\nThe proportions for coapplicant income zero - for various loan status:\n')
prop.table(tab,2)
 

#checking if some relation between education and loan status
tab <- table(loan_status=loan_train1$Loan_Status,education=loan_train1$Education)
cat('\nThe proportions of education - for various loan status:\n')
prop.table(tab,2)


#checking if some relation between marital status and loan status
tab <- table(loan_status=loan_train1$Loan_Status,married=loan_train1$Married)
cat('\nThe proportions of marital status - for various loan status:\n')
prop.table(tab,2)

#checking if some relation between number of dependents and loan status
tab <- table(loan_status=loan_train1$Loan_Status,num_of_dependents=loan_train1$Dependents)
cat('\nThe proportions of number of dependents - for various loan status:\n')
prop.table(tab,2)


#checking if some relation between property area and loan status
tab <- table(loan_status=loan_train1$Loan_Status,prop_area=loan_train1$Property_Area)
cat('\nThe proportions of property area - for various loan status:\n')
prop.table(tab,2)

```

Can infer that:

- The loans that got approved are the ones that took less loan amount compared to that of rejected.
- Applicant income doesn't seem different for approved/rejected loans
- As applicant income increases, loan amount increases. The rejected cases are mostly the ones with more loan amount and lesser applicant income (though there are lots of outliers)
- There seems no relation between self employment and loan status (approved cases for both self employed and non-self employed is same - 68%)
- The approved cases for credit_history "1" customers is significantly high(79%) than credit_history "0" customers(31%)
- The approval rate for cases where there is coaaplicant income is higher(71%) than cases where there is no coapplicant income(64%).
- The approval rate for cases where the applicant is married is higher(71%) than cases where there the applicant is not married(62%).
- The approval rate for cases where the number of dependents is <3 is greater than cases where there the number of dependents is 3+ 
- The approval rate for urban and semiurban(65% and 76%) properties is greater than rural properties(61%) 



### Splitting the data into train and validation set (70-30)

```{r}

set.seed(10)
loan_idx <- sample(1:nrow(loan_train1),0.7*nrow(loan_train1))
app_train <- loan_train1[loan_idx,]
app_val <- loan_train1[-loan_idx,]

```

### Logistic regression (Training the model)

```{r}

#Below is the model with significant variables after trying multiple combinations

logit.modelt <- glm(Loan_Status ~ Credit_History+Property_Area+LoanAmount+Married, family = 'binomial', data = app_train)


summary(logit.modelt)

```

Can infer below:

-  Credit_History, Property_Area, LoanAmount and Married are significant to the logistic regression model



### Logistic regression (Validation)
### Since the number of observations are less, it is better to use K-fold cross validation for correct assesment of accuracy/error in the model

```{r}

k = 10 #Folds
data <- loan_train1

# sample from 1 to k, nrow times (the number of observations in the data)
set.seed(11)
data$id <- sample(1:k, nrow(data), replace = TRUE)
table(data$id)

# prediction data frame that we add to with each iteration over the folds

prediction <- data.frame()


for (i in 1:k)
  {
  # select rows with id i to create test set
  # remove rows with id i from dataframe to create training set
  testset <- data %>% filter(id==i)
  trainingset <- setdiff(data,testset)
  
  # run the model
 
  mymodel <- glm(Loan_Status ~ Credit_History+Property_Area+LoanAmount+Married, family = 'binomial', data = trainingset)

  
  # predict Loan Status
  
  temp.probs <- predict(mymodel, testset,type='response')
  temp.pred <- rep('N',length(testset$Loan_Status))
  temp.pred[temp.probs>0.5]='Y'
  c1 <- confusionMatrix(table(predicted=temp.pred,actual=testset$Loan_Status),positive = 'Y')
  
  temp1 <- cbind(Accuracy=c1$overall[['Accuracy']],Sensitivity=c1$byClass[['Sensitivity']],Specificity=c1$byClass[['Specificity']],Precision=c1$byClass[['Precision']])
  
  # append this iteration's accuracy from confusion matrix to the end of data frame
  prediction <- rbind(prediction, temp1 ) 
  

}

# Use Mean Accuracy as Evalution 

k_evaluate <- sapply(prediction[,1:4],mean); k_evaluate


```

Can infer that:

- Accuracy of Logistic regression model is 0.77

### Decision Tree


```{r}

library(tree)

tree1 <- tree(Loan_Status ~ .,data=app_train)
summary(tree1)

plot(tree1)
text(tree1)

tree.pred <- predict(tree1,app_val,type='class')
confusionMatrix(tree.pred,app_val$Loan_Status,positive = 'Y')


```

Can infer that:

- Accuracy of model is 0.72. That means missclassification is pretty high (0.28)
- So there is need to prune the tree


### Prune the tree
### Cross validate to check where to stop pruning

```{r}

set.seed(12)

cv_tree <- cv.tree(tree1,FUN=prune.misclass)
names(cv_tree)
plot(cv_tree$size,cv_tree$dev,type='b')


#cv_tree1 <- cv.tree(tree1,FUN=prune.tree)
#names(cv_tree1)

```

### Prune the tree

```{r}

pruned_model <- prune.misclass(tree1,best=2)
plot(pruned_model)
text(pruned_model)

```


### Check how is it doing

```{r}

tree.pred <- predict(pruned_model,app_val,type='class')
confusionMatrix(tree.pred,app_val$Loan_Status,positive = 'Y')


```

